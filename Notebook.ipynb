{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supreme Court Decision Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = pd.read_csv('csvs/justice2.csv')\n",
    "judges = pd.read_csv('csvs/table_of_justices.csv')\n",
    "presidents = pd.read_csv('csvs/presidents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3303 entries, 0 to 3302\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          3303 non-null   int64 \n",
      " 1   ID                  3303 non-null   int64 \n",
      " 2   name                3303 non-null   object\n",
      " 3   href                3303 non-null   object\n",
      " 4   docket              3292 non-null   object\n",
      " 5   term                3303 non-null   int64 \n",
      " 6   first_party         3302 non-null   object\n",
      " 7   second_party        3302 non-null   object\n",
      " 8   facts               3303 non-null   object\n",
      " 9   facts_len           3303 non-null   int64 \n",
      " 10  majority_vote       3303 non-null   int64 \n",
      " 11  minority_vote       3303 non-null   int64 \n",
      " 12  first_party_winner  3288 non-null   object\n",
      " 13  decision_type       3296 non-null   object\n",
      " 14  disposition         3231 non-null   object\n",
      " 15  issue_area          3161 non-null   object\n",
      "dtypes: int64(6), object(10)\n",
      "memory usage: 413.0+ KB\n"
     ]
    }
   ],
   "source": [
    "cases.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121 entries, 0 to 120\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Index                     121 non-null    int64 \n",
      " 1   Justice Name              121 non-null    object\n",
      " 2   Supreme Court Term Start  121 non-null    object\n",
      " 3   Supreme Court Term End    121 non-null    object\n",
      " 4   Appointing President      121 non-null    object\n",
      " 5   Notable Opinion(s)        121 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "judges.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's nice to note that there isn't any missing information regarding the entered judges here. Every judge has\n",
    "* Name\n",
    "* Start Term\n",
    "* End Term\n",
    "* Appointing President\n",
    "\n",
    "This will help us to potentially classify the judge's political affiliations when creating features for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46 entries, 0 to 45\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   President   46 non-null     object\n",
      " 1   Party       46 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 864.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "presidents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get All Dates in Terms of Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_19676\\760960972.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  judges['end_year'] = pd.to_datetime(judges['Supreme Court Term End'].replace(\"--\",\"01-Mar-24\")).dt.year\n"
     ]
    }
   ],
   "source": [
    "judges['start_year'] = pd.to_datetime(judges['Supreme Court Term Start']).dt.year\n",
    "judges['end_year'] = pd.to_datetime(judges['Supreme Court Term End'].replace(\"--\",\"01-Mar-24\")).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All cases just have a \"term\" in which a ruling was placed, not an actual date. Therefore, we will need to make an assumption that if a Supreme Court Justice's service encapsulates the term in which a ruling was passed, they will in fact have had been part of that ruling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match Judges to their Party Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "judges['president_last_name'] = judges[\"Appointing President\"].str.extract(r'^(\\w+),')\n",
    "presidents['president_last_name']= presidents['President '].str.extract(r'\\s(\\w+)$') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_party_dict = presidents.set_index('president_last_name')['Party '].to_dict()\n",
    "judges['party'] = np.where(judges['president_last_name'].isin(president_party_dict.keys()),\n",
    "                           judges['president_last_name'].map(president_party_dict),\n",
    "                           None)\n",
    "judges['party'] = judges['party'].dropna().apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the assumption that the judges will have the same political affiliation as the President that inaugarated him/her. Therefore, it is helpful to map the President's party affiliation to the corresponding Supreme Court Justices they appointed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party\n",
       "Republican                                   49\n",
       "Democratic                                   44\n",
       "Independent                                  11\n",
       "Democratic-Republican                         6\n",
       "Republican/National Union                     5\n",
       "Democratic-Republican/National Republican     4\n",
       "Whig                                          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judges.value_counts(\"party\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a problem that was unforseen. There have been some different sounding political parties over the years with some unique ideals. It's hard to classify distinction with the change of names because...\n",
    "\n",
    "`Democratic` + `Republican` != `Democratic-Republican`\n",
    "\n",
    "Our solution here is to instead to map party ideology into \"neutral\", \"conservative\", or \"liberal\" utilizing our pre-existing knowledge of these parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideology_map = {\n",
    "    \"Republican\": \"conservative\",\n",
    "    \"Democratic\": \"liberal\",\n",
    "    \"Independent\": \"neutral\", \n",
    "    \"Whig\": \"conservative\",\n",
    "    \"Democratic-Republican/National Republican\": \"conservative\",\n",
    "    \"Republican/National Union\": \"conservative\",\n",
    "    \"Democratic-Republican\": \"liberal\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "judges['ideology'] = np.where(judges['party'].isin(ideology_map.keys()),\n",
    "                           judges['party'].map(ideology_map),\n",
    "                           None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match Cases to Judges to Get Counts for Each Ideology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases[\"conservative\"] = 0\n",
    "cases[\"liberal\"] = 0\n",
    "cases[\"neutral\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case_index, term in enumerate(cases.term):\n",
    "    for judge_index, (start, end) in enumerate(zip(judges.start_year, judges.end_year)):\n",
    "        if (start <= term <= end):\n",
    "            judge_ideology = judges.ideology[judge_index]\n",
    "            cases.loc[case_index, judge_ideology] += 1\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Rows Missing \"`Issue_area` \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.loc[cases.issue_area.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularize Facts Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\brand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\brand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\brand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    ''' Tokenize document text by stripping the text into individual tokens, removing digit characters, removing punctuation, remove stop words, and lemmatizing the tokens.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The body of text that you would like to tokenize\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cleaned_doc_tokens : str\n",
    "        The cleaned and tokenized text\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    text = \"Hailey Naugle was quite the important contributor to this Supreme Court analysis. - Brandon Owens\"\n",
    "\n",
    "    clean_text = tokenizer(text)\n",
    "    \n",
    "    Will output:\n",
    "        \"hailey naugle important contributor supreme court analysis brandon owens\"\n",
    "\n",
    "    '''\n",
    "\n",
    "    text_tokens = []\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        sent_tokens = nltk.word_tokenize(sentence)\n",
    "        sent_tokens = [lemmatizer.lemmatize(word.lower()) for word in sent_tokens \n",
    "                       if (word.lower() not in stop_words) and (word not in string.punctuation) and (len(word) > 1) and not(word.isdigit())]\n",
    "        text_tokens += sent_tokens\n",
    "\n",
    "    cleaned_doc_tokens = ' '.join(text_tokens)\n",
    "\n",
    "    return cleaned_doc_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases[\"cleaned_facts\"] = cases[\"facts\"].apply(lambda x: tokenizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Target Column to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.first_party_winner = cases.first_party_winner.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hey Hails, not sure how you wanted to do the baseline/null model here for something to compare to. It's your call**\n",
    "\n",
    "**Also, I got rid of the \"unanimous\" section you added just because under the decision type, per-curiam means unanimous according to Google I guess?**\n",
    "\n",
    "**Why don't we pick out some models to eventually try -- I haven't finished with the nlp stuff yet. I still want to do a lot with it in the EDA, I just had to prep a tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into test and train data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
